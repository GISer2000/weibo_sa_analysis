{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c759980c-07cb-4d36-9d53-afc0a037f6ad",
   "metadata": {},
   "source": [
    "<center><font size=6>微博情感分析</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4767b1f-e5c2-4611-b3dd-4c3ea2685ecb",
   "metadata": {},
   "source": [
    "## 模型训练说明\n",
    "模型基于BERT-chinse-base进行finetune\n",
    "* 请在根目录下创建目标目录（若已创建，则跳过）\n",
    "* 请将此notebook另存到上一步所创建的目录下\n",
    "* 请初始化相关路径变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42bc4efc-a370-43d2-80df-248fd35465ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5.4\n"
     ]
    }
   ],
   "source": [
    "! jupyter notebook --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536144f2-1930-44c4-b68f-89b24843fd0d",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd00e349-21aa-4b53-aa4e-cf48e16d5529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = 'My_Model'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import transformers\n",
    "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import trange, notebook\n",
    "from tqdm import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ac6974-123c-4045-b492-af789ff7cab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.1+cu117\n",
      "transformers version: 4.27.1\n"
     ]
    }
   ],
   "source": [
    "print(f'torch version: {torch.__version__}\\ntransformers version: {transformers.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f66fc6-c18c-45d0-93e3-0d7d12bcd91d",
   "metadata": {},
   "source": [
    "## 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe0b37e-a3ca-4d62-8b2d-e385c9d0bf6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../model/bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../model/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-chinese'\n",
    "# 下面三个文件的路径为 bert-base-chinese 文件夹，根据自己的存储路径更换\n",
    "config = BertConfig.from_pretrained('model/'+model_name, finetuning_task='binary')  # BERT 模型配置\n",
    "tokenizer = BertTokenizer.from_pretrained('model/'+model_name)  # BERT 的分词器\n",
    "model = BertForSequenceClassification.from_pretrained('model/'+model_name, num_labels=2)  # BERT 的文本分类模型\n",
    " \n",
    "# 用于将文本转换为BERT模型的输入标记\n",
    "def get_tokens(text, tokenizer, max_seq_length, add_special_tokens=True): \n",
    "    # 使用分词器将文本转换为模型可以接受的输入格式\n",
    "    input_ids = tokenizer.encode(text,\n",
    "                                 add_special_tokens=add_special_tokens,\n",
    "                                 truncation=True,\n",
    "                                 max_length=max_seq_length,\n",
    "                                 pad_to_max_length=True)\n",
    "    # 创建一个关注掩码，标记哪些标记是真实文本标记\n",
    "    attention_mask = [int(id > 0) for id in input_ids]\n",
    "    # 确保输入标记和关注掩码的长度等于最大序列长度\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(attention_mask) == max_seq_length\n",
    "    return (input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea08d49-2242-4a8a-bd64-d4db567fe815",
   "metadata": {},
   "source": [
    "## 导入标注数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950bfbc4-8308-46e4-8322-2c5e6100cc6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 目标：保留话题的文字、移除poi超链接、视频超链接、保留表情图片中的标题文字、移除其他html标签\n",
    "def prepare(text):\n",
    "    import re\n",
    "    # 删除包含 wbicon 的 <i> 标签以及它们之间的内容\n",
    "    tokens = re.sub(re.compile(r'(<i\\s+.*?wbicon.*?>.*?</i>)', re.S), '', text)\n",
    "    # 删除与 HTML 匹配的标签，包括尖括号 < 和 > 之间的内容\n",
    "    tokens = re.sub(re.compile(r'<(.*?)>', re.S), '', text)\n",
    "    # 保留 <img title=\"xxx\"> 中的 title 信息\n",
    "    tokens = re.sub(re.compile(r'<img.*?(alt=[\"|\\']{0,1}(.*?)[\"|\\']{0,1}|title=[\"|\\']{0,1}(.*?)[\"|\\']{0,1})\\s+.*?>', re.S|re.M), '\\g<2>', text).strip()\n",
    "    # 将匹配到的 <br/> 替换为 \\n\n",
    "    tokens = re.sub(re.compile(r'<br/>',re.S),'\\n',text)\n",
    "    # 移除文本内的连续重复内容\n",
    "    # 移除连续发生3次及以上次数的重复性内容\n",
    "    # 重复内容的字符串长度>=3\n",
    "    tokens = re.sub(re.compile(r'([\\s|\\S]{2,}?)\\1{2,}',re.S|re.M),'\\g<1>',text)\n",
    "    # 移除 poi链接、视频链接、直播链接\n",
    "    urls=re.findall(r\"<a.*?href=.*?<\\/a>\", text, re.I|re.S|re.M)\n",
    "    url=[u for u in urls if '>2<' in u or 'location_default.png' in u or '视频</a>' in u or '视频</span></a>' in u or '直播</a>' in u]\n",
    "    if len(url)>0:\n",
    "        for u in url:\n",
    "            tokens=text.replace(u,'')\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1567ce2-7abb-4d2e-b563-53209b1b65fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('data/weibo_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98691b3c-5468-4793-91e5-64d02080afdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=psutil.cpu_count(logical=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c190e154-2996-4d3a-950d-f74cd84c85d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label['message'] = df_label['message'].parallel_apply(prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f34230-b9f0-4750-a495-a7613de7fc24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       " 0    2771\n",
       " 1    2102\n",
       "-1     683\n",
       " 6     638\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703bd6a-6e07-4b9e-8e42-05694b28a221",
   "metadata": {},
   "source": [
    "## 垃圾文本预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6dc64e-843a-4d21-9992-5a01abc7cc46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_label.copy()\n",
    "df.loc[df[df.sentiment!=6].index,'sentiment'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62eff7da-3af7-4f07-9918-efd1e79707da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[(df['sentiment']==1)|(df['sentiment']==6)]\n",
    "# 随机丢弃标注列表中量较多的数据，以保持二者的标注量基本相同，提高后期模型预测的准确率\n",
    "drop_size = len(df[df['sentiment']==1].sentiment)-len(df[df['sentiment']==6].sentiment)\n",
    "df.drop(df[df['sentiment']==1].sample(drop_size).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6c3478-ce7f-4162-9fe9-d1382df12b49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3fab18-bfa6-455e-a673-0bdeb865d702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df[df.sentiment==6].index,'sentiment'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6bfbd99-9871-4605-b7a3-a3e19727bc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92ca71f8-6026-4bdd-b0b1-4013e67a043e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>4818951786202064</td>\n",
       "      <td>#一条plog告别九月# [二哈]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>4820570703136111</td>\n",
       "      <td>🌄 🌅</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>4260379876100120</td>\n",
       "      <td>分享图片</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>4260900208896280</td>\n",
       "      <td>分享视频</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>4260015919234630</td>\n",
       "      <td>睡前打卡[月亮]  酵素果冻水果味，大人小孩都爱吃[耶]    排毒 养颜，清肠 治便秘，净...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>4821704956706891</td>\n",
       "      <td>江同学，你好，我是f班的袁湘琴。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4262178615743880</td>\n",
       "      <td>只有几件抹胸吊带裙。随便秒杀￥75包邮。  夏季出游拍图美美哒</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>4262059300643330</td>\n",
       "      <td>7.17 薛之谦   \\n 唯爱薛之谦@薛之谦 \\n #薛之谦717生日快乐##薛之谦##薛...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>4820576437276314</td>\n",
       "      <td>迷途漫漫，终有一归🌈</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>4260256810421990</td>\n",
       "      <td>一叶孤……</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mid                                            message  \\\n",
       "5879  4818951786202064                                  #一条plog告别九月# [二哈]   \n",
       "4461  4820570703136111                                                🌄 🌅   \n",
       "731   4260379876100120                                               分享图片   \n",
       "2358  4260900208896280                                               分享视频   \n",
       "199   4260015919234630  睡前打卡[月亮]  酵素果冻水果味，大人小孩都爱吃[耶]    排毒 养颜，清肠 治便秘，净...   \n",
       "5723  4821704956706891                                   江同学，你好，我是f班的袁湘琴。   \n",
       "96    4262178615743880                    只有几件抹胸吊带裙。随便秒杀￥75包邮。  夏季出游拍图美美哒   \n",
       "1072  4262059300643330  7.17 薛之谦   \\n 唯爱薛之谦@薛之谦 \\n #薛之谦717生日快乐##薛之谦##薛...   \n",
       "4703  4820576437276314                                         迷途漫漫，终有一归🌈   \n",
       "1905  4260256810421990                                              一叶孤……   \n",
       "\n",
       "      sentiment  \n",
       "5879          0  \n",
       "4461          0  \n",
       "731           0  \n",
       "2358          0  \n",
       "199           0  \n",
       "5723          1  \n",
       "96            0  \n",
       "1072          1  \n",
       "4703          1  \n",
       "1905          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a62507-31a1-4225-8d22-2284812dee14",
   "metadata": {},
   "source": [
    "### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f5500ea-4141-450f-b7b8-9eb5a9ad8f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['message'],  # 文本消息数据\n",
    "                                                    df['sentiment'],  # 文本情感标签\n",
    "                                                    test_size=0.2,    # 测试集占总数据的比例\n",
    "                                                    random_state=42,  # 随机种子，以确保可重复性\n",
    "                                                    stratify=df['sentiment'])  # 根据情感标签进行分层抽样\n",
    "# 使用自定义函数 get_tokens 对训练集和测试集的文本进行分词，每个文本最多包含150个标记\n",
    "X_train_tokens = X_train.apply(get_tokens, args=(tokenizer, 150))\n",
    "X_test_tokens = X_test.apply(get_tokens, args=(tokenizer, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641134b-84f6-4d73-9511-d73a01a6d92a",
   "metadata": {},
   "source": [
    "### 训练准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a28e42b5-7a17-4b1a-8d19-1f3d21117ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将训练集的文本特征转换为PyTorch张量\n",
    "input_ids_train = torch.tensor(\n",
    "    [features[0] for features in X_train_tokens.values], dtype=torch.long)  # 输入特征 ID\n",
    "input_mask_train = torch.tensor(\n",
    "    [features[1] for features in X_train_tokens.values], dtype=torch.long)  # 输入掩码\n",
    "label_ids_train = torch.tensor(Y_train.values, dtype=torch.long)  # 标签 ID\n",
    "\n",
    "# # 输出训练集张量的形状\n",
    "# print(input_ids_train.shape)  # 输出训练集输入特征的形状\n",
    "# print(input_mask_train.shape)  # 输出训练集输入掩码的形状\n",
    "# print(label_ids_train.shape)  # 输出训练集标签的形状\n",
    "\n",
    "# 创建训练数据集\n",
    "train_dataset = TensorDataset(input_ids_train, input_mask_train, label_ids_train)\n",
    "\n",
    "# 将测试集的文本特征转换为PyTorch张量\n",
    "input_ids_test = torch.tensor([features[0] for features in X_test_tokens.values], dtype=torch.long)\n",
    "input_mask_test = torch.tensor([features[1] for features in X_test_tokens.values], dtype=torch.long)\n",
    "label_ids_test = torch.tensor(Y_test.values, dtype=torch.long)\n",
    "\n",
    "# 创建测试数据集\n",
    "test_dataset = TensorDataset(input_ids_test, input_mask_test, label_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "785affc9-19b3-49c5-92ad-857f45079ade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数量 = 1020\n",
      "训练周期数 = 3\n",
      "总的训练批次大小 = 64\n",
      "总的优化步数 = 5\n"
     ]
    }
   ],
   "source": [
    "# 训练批次大小和训练周期数\n",
    "train_batch_size = 64\n",
    "num_train_epochs = 3\n",
    "\n",
    "# 创建训练数据采样器和数据加载器\n",
    "train_sampler = RandomSampler(train_dataset)  # 随机采样器，用于随机选择训练样本\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              sampler=train_sampler, \n",
    "                              batch_size=train_batch_size)  # 创建训练数据加载器\n",
    "t_total = len(train_dataloader) // num_train_epochs  # 计算总的训练步数\n",
    "\n",
    "# 输出一些训练相关的信息\n",
    "print(\"样本数量 =\", len(train_dataset))  # 输出训练集样本数量\n",
    "print(\"训练周期数 =\", num_train_epochs)  # 输出训练周期数\n",
    "print(\"总的训练批次大小 =\", train_batch_size)  # 输出总的训练批次大小\n",
    "print(\"总的优化步数 =\", t_total)  # 输出总的优化步数\n",
    "\n",
    "# 优化器和学习率调度器的设置\n",
    "learning_rate = 5e-5  # 学习率\n",
    "adam_epsilon = 1e-8  # Adam优化器的epsilon值\n",
    "warmup_steps = 0  # 学习率预热步数\n",
    "\n",
    "# 创建AdamW优化器和学习率调度器\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=t_total)  # 创建学习率调度器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce40dd-e1d7-44b7-a044-3b40dcb06b59",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7da300f5-432d-460b-9586-f894de84285f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|▋         | 1/16 [00:02<00:38,  2.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▎        | 2/16 [00:03<00:22,  1.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▉        | 3/16 [00:04<00:16,  1.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|██▌       | 4/16 [00:05<00:13,  1.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.478594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|███▏      | 5/16 [00:06<00:11,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|███▊      | 6/16 [00:07<00:09,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.479835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|████▍     | 7/16 [00:07<00:08,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.417668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|█████     | 8/16 [00:08<00:07,  1.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.513813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|█████▋    | 9/16 [00:09<00:06,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|██████▎   | 10/16 [00:10<00:05,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.472073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|██████▉   | 11/16 [00:11<00:04,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.442426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|███████▌  | 12/16 [00:12<00:03,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|████████▏ | 13/16 [00:13<00:02,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%|████████▊ | 14/16 [00:14<00:01,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|█████████▍| 15/16 [00:15<00:00,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 100%|██████████| 16/16 [00:16<00:00,  1.00s/it]\u001b[A\n",
      "Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.05s/it]\n",
      "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.527742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|▋         | 1/16 [00:00<00:13,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▎        | 2/16 [00:01<00:12,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.486746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▉        | 3/16 [00:02<00:11,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|██▌       | 4/16 [00:03<00:10,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.443561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|███▏      | 5/16 [00:04<00:09,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|███▊      | 6/16 [00:05<00:09,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.463012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|████▍     | 7/16 [00:06<00:08,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.445318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|█████     | 8/16 [00:07<00:07,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.422389"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|█████▋    | 9/16 [00:08<00:06,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|██████▎   | 10/16 [00:09<00:05,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|██████▉   | 11/16 [00:09<00:04,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.487049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|███████▌  | 12/16 [00:10<00:03,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.547127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|████████▏ | 13/16 [00:11<00:02,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.439794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%|████████▊ | 14/16 [00:12<00:01,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.450694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|█████████▍| 15/16 [00:13<00:00,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.470267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 100%|██████████| 16/16 [00:14<00:00,  1.11it/s]\u001b[A\n",
      "Epoch:  67%|██████▋   | 2/3 [00:30<00:15, 15.10s/it]\n",
      "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.565314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|▋         | 1/16 [00:00<00:13,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.522709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▎        | 2/16 [00:01<00:12,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.482386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▉        | 3/16 [00:02<00:11,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|██▌       | 4/16 [00:03<00:10,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.488819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|███▏      | 5/16 [00:04<00:09,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.441887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|███▊      | 6/16 [00:05<00:09,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|████▍     | 7/16 [00:06<00:08,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.470273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|█████     | 8/16 [00:07<00:07,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.452852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|█████▋    | 9/16 [00:08<00:06,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.523107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|██████▎   | 10/16 [00:09<00:05,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|██████▉   | 11/16 [00:09<00:04,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|███████▌  | 12/16 [00:10<00:03,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.439552"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|████████▏ | 13/16 [00:11<00:02,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.446591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%|████████▊ | 14/16 [00:12<00:01,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|█████████▍| 15/16 [00:13<00:00,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.487008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 100%|██████████| 16/16 [00:14<00:00,  1.11it/s]\u001b[A\n",
      "Epoch: 100%|██████████| 3/3 [00:44<00:00, 14.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# 检测是否有GPU可用，如果有则使用GPU，否则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 创建一个描述训练周期的迭代器\n",
    "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
    "\n",
    "# 将模型置于 train 模式\n",
    "model.train()\n",
    "\n",
    "for epoch in train_iterator:\n",
    "    # 创建一个描述迭代的迭代器\n",
    "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        # 重置每个迭代开始时的所有梯度\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # 将模型和输入数据移到GPU（如果可用）\n",
    "        # torch.cuda.empty_cache()  # 清理GPU缓存\n",
    "        model.to(device)  # 将模型移到GPU或CPU\n",
    "        cuda = next(model.parameters()).device\n",
    "        batch = tuple(t.to(cuda) for t in batch)  # 将批次数据移到GPU或CPU\n",
    "\n",
    "        # 确定传递给模型的输入\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],      # 输入特征ID\n",
    "            'attention_mask': batch[1], # 输入掩码\n",
    "            'labels': batch[2]         # 标签\n",
    "        }\n",
    "\n",
    "        # 通过模型进行前向传播：输入 -> 模型 -> 输出\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 打印当前损失值\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "        # 反向传播损失，自动计算梯度\n",
    "        loss.backward()\n",
    "\n",
    "        # 通过将梯度限制在一定范围内来防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 更新模型参数和学习率\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc9836-c655-4d17-a121-39ed2f1bfc54",
   "metadata": {
    "tags": []
   },
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5cb1d03-e65f-4760-9bbf-8a2f1e9172f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('My_Model/weibo-bert-rubbish-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3d3e9-7c87-41ca-a98a-27f2d72e98af",
   "metadata": {},
   "source": [
    "### 验证模型并评估精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4d3998d-4834-4c99-a9ba-0f05444c2bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估中: 100%|██████████| 4/4 [00:01<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集中的Accuracy分数:  0.8046875\n",
      "测试集中的F1分数:  0.8299319727891157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试批次大小\n",
    "test_batch_size = 64\n",
    "\n",
    "# 创建测试数据采样器和数据加载器\n",
    "test_sampler = SequentialSampler(test_dataset)  # 顺序采样器，用于顺序选择测试样本\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             sampler=test_sampler, \n",
    "                             batch_size=test_batch_size)  # 创建测试数据加载器\n",
    "\n",
    "# 加载之前保存的预训练模型\n",
    "# model = model.from_pretrained('/outputs')\n",
    "\n",
    "# 初始化预测和实际标签\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "\n",
    "# 将模型置于 eval 模式\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(test_dataloader, desc=\"评估中\"):\n",
    "    # 将模型和输入数据移到GPU（如果可用）\n",
    "    model.to(device)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 在 eval 模式下不跟踪任何梯度\n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],  # 输入特征ID\n",
    "            'attention_mask': batch[1],  # 输入掩码\n",
    "            'labels': batch[2]  # 标签\n",
    "        }        \n",
    "\n",
    "        # 通过模型进行前向传播\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # 我们得到损失，因为我们提供了标签\n",
    "        tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "        # 测试数据集可能包含多个批次的项目\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, \n",
    "                                      inputs['labels'].detach().cpu().numpy(), \n",
    "                                      axis=0)\n",
    "\n",
    "# 计算最终损失、预测和准确度\n",
    "preds = np.argmax(preds, axis=1)  # 获取预测类别\n",
    "acc_score = accuracy_score(preds, out_label_ids)  # 计算准确度\n",
    "f1_score = f1_score(preds, out_label_ids)  # 计算F1分数\n",
    "print ('测试集中的Accuracy分数: ', acc_score)\n",
    "print ('测试集中的F1分数: ', f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84094fb-144f-44a2-90a6-0c02c2d51972",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2572953e-4b99-4fdf-80f2-a1a322c174d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userid</th>\n",
       "      <th>message</th>\n",
       "      <th>ts_created</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4817910549973967</td>\n",
       "      <td>6339251717</td>\n",
       "      <td>记录一下合肥一日游[送花花][送花花]</td>\n",
       "      <td>2022-09-26 11:27:30</td>\n",
       "      <td>0</td>\n",
       "      <td>记录一下合肥一日游[送花花][送花花]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4817738155690682</td>\n",
       "      <td>6080243764</td>\n",
       "      <td>真诚才是爱的秘密</td>\n",
       "      <td>2022-09-26 00:02:28</td>\n",
       "      <td>0</td>\n",
       "      <td>真诚才是爱的秘密</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4819531555412098</td>\n",
       "      <td>5867909333</td>\n",
       "      <td>回家[给力]</td>\n",
       "      <td>2022-09-30 22:48:48</td>\n",
       "      <td>0</td>\n",
       "      <td>回家[给力]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4818048550179045</td>\n",
       "      <td>3289196050</td>\n",
       "      <td>躺平大师</td>\n",
       "      <td>2022-09-26 20:35:52</td>\n",
       "      <td>0</td>\n",
       "      <td>躺平大师</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4819813207117305</td>\n",
       "      <td>6495662753</td>\n",
       "      <td>终于[泪]</td>\n",
       "      <td>2022-10-01 17:27:59</td>\n",
       "      <td>0</td>\n",
       "      <td>终于[泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25989</th>\n",
       "      <td>4820530244883475</td>\n",
       "      <td>6219366090</td>\n",
       "      <td>热傻了今天</td>\n",
       "      <td>2022-10-03 16:57:14</td>\n",
       "      <td>0</td>\n",
       "      <td>热傻了今天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25990</th>\n",
       "      <td>4821179631666949</td>\n",
       "      <td>6557015016</td>\n",
       "      <td>#挪威海底电缆断裂#北约除了干瞪眼！实在做不出别的事情  跟北溪二号一样  哑巴吃黄连，有苦...</td>\n",
       "      <td>2022-10-05 11:57:40</td>\n",
       "      <td>0</td>\n",
       "      <td>#挪威海底电缆断裂#北约除了干瞪眼！实在做不出别的事情  跟北溪二号一样  哑巴吃黄连，有苦...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25991</th>\n",
       "      <td>4821641589163051</td>\n",
       "      <td>5639007389</td>\n",
       "      <td>今天：合肥下雨了，晚上加班到十点半 不过还好，心情不是很糟糕 我还是心心念念想要养一只小猫</td>\n",
       "      <td>2022-10-06 18:33:19</td>\n",
       "      <td>0</td>\n",
       "      <td>今天：合肥下雨了，晚上加班到十点半 不过还好，心情不是很糟糕 我还是心心念念想要养一只小猫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25992</th>\n",
       "      <td>4818771782408232</td>\n",
       "      <td>2072019043</td>\n",
       "      <td>参观晚清重臣李鸿章故居，重温那段风云变幻的历史，不胜感慨！“时来天地皆同力，运去英雄不自由”...</td>\n",
       "      <td>2022-09-28 20:29:44</td>\n",
       "      <td>0</td>\n",
       "      <td>参观晚清重臣李鸿章故居，重温那段风云变幻的历史，不胜感慨！“时来天地皆同力，运去英雄不自由”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25993</th>\n",
       "      <td>4820203500212621</td>\n",
       "      <td>6052311057</td>\n",
       "      <td>分享图片</td>\n",
       "      <td>2022-10-02 19:18:52</td>\n",
       "      <td>0</td>\n",
       "      <td>分享图片</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25994 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id      userid  \\\n",
       "0      4817910549973967  6339251717   \n",
       "1      4817738155690682  6080243764   \n",
       "2      4819531555412098  5867909333   \n",
       "3      4818048550179045  3289196050   \n",
       "4      4819813207117305  6495662753   \n",
       "...                 ...         ...   \n",
       "25989  4820530244883475  6219366090   \n",
       "25990  4821179631666949  6557015016   \n",
       "25991  4821641589163051  5639007389   \n",
       "25992  4818771782408232  2072019043   \n",
       "25993  4820203500212621  6052311057   \n",
       "\n",
       "                                                 message           ts_created  \\\n",
       "0                                    记录一下合肥一日游[送花花][送花花]  2022-09-26 11:27:30   \n",
       "1                                               真诚才是爱的秘密  2022-09-26 00:02:28   \n",
       "2                                                 回家[给力]  2022-09-30 22:48:48   \n",
       "3                                                   躺平大师  2022-09-26 20:35:52   \n",
       "4                                                  终于[泪]  2022-10-01 17:27:59   \n",
       "...                                                  ...                  ...   \n",
       "25989                                              热傻了今天  2022-10-03 16:57:14   \n",
       "25990  #挪威海底电缆断裂#北约除了干瞪眼！实在做不出别的事情  跟北溪二号一样  哑巴吃黄连，有苦...  2022-10-05 11:57:40   \n",
       "25991      今天：合肥下雨了，晚上加班到十点半 不过还好，心情不是很糟糕 我还是心心念念想要养一只小猫  2022-10-06 18:33:19   \n",
       "25992  参观晚清重臣李鸿章故居，重温那段风云变幻的历史，不胜感慨！“时来天地皆同力，运去英雄不自由”...  2022-09-28 20:29:44   \n",
       "25993                                               分享图片  2022-10-02 19:18:52   \n",
       "\n",
       "       label                                               text  \n",
       "0          0                                记录一下合肥一日游[送花花][送花花]  \n",
       "1          0                                           真诚才是爱的秘密  \n",
       "2          0                                             回家[给力]  \n",
       "3          0                                               躺平大师  \n",
       "4          0                                              终于[泪]  \n",
       "...      ...                                                ...  \n",
       "25989      0                                              热傻了今天  \n",
       "25990      0  #挪威海底电缆断裂#北约除了干瞪眼！实在做不出别的事情  跟北溪二号一样  哑巴吃黄连，有苦...  \n",
       "25991      0      今天：合肥下雨了，晚上加班到十点半 不过还好，心情不是很糟糕 我还是心心念念想要养一只小猫  \n",
       "25992      0  参观晚清重臣李鸿章故居，重温那段风云变幻的历史，不胜感慨！“时来天地皆同力，运去英雄不自由”...  \n",
       "25993      0                                               分享图片  \n",
       "\n",
       "[25994 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin = pd.read_csv('data/weibo_origin.csv')\n",
    "df_origin['label'] = 0 #统一初始化为0\n",
    "df_origin['text'] = df_origin.message.str.replace('\\n',' ')\n",
    "df_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd3f6934-f2ea-4f8e-b8b7-72365fddbd69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_pred=df_origin['text']\n",
    "Y_pred=df_origin['label']\n",
    "X_pred_tokens = X_pred.parallel_apply(get_tokens, args=(tokenizer, 150))\n",
    "\n",
    "input_ids_pred = torch.tensor(\n",
    "    [features[0] for features in X_pred_tokens.values], dtype=torch.long)\n",
    "input_mask_pred = torch.tensor(\n",
    "    [features[1] for features in X_pred_tokens.values], dtype=torch.long)\n",
    "label_pred=torch.tensor(Y_pred.values,dtype=torch.long)\n",
    "pred_dataset = TensorDataset(input_ids_pred,input_mask_pred,label_pred)\n",
    "\n",
    "pred_batch_size = 256\n",
    "pred_sampler = SequentialSampler(pred_dataset)\n",
    "pred_dataloader = DataLoader(pred_dataset, \n",
    "                             sampler=pred_sampler, \n",
    "                             batch_size=pred_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80770caf-be1e-4ef4-b238-87559a811395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用训练好的模型\n",
    "model = model.from_pretrained('My_Model/weibo-bert-rubbish-model')\n",
    "preds = None\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc7dcfb9-ee43-44f0-acdb-e087db298e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict: 100%|██████████| 102/102 [00:36<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for batch in tqdm(pred_dataloader, desc=\"Predict\"):\n",
    "    \n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        _, logits = outputs[:2]\n",
    "\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "794aa31a-3dd7-46dd-89e6-99817b373d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.softmax(torch.tensor(preds), dim=1)  # 使用softmax函数计算预测的概率分布\n",
    "preds = np.argmax(preds, axis=1)  # 计算每个样本的最终预测类别\n",
    "df_origin['ad_prob'] = [p[1].item() for p in prob]  # 将概率分布的第二列（表示\"1\"类别的概率）添加到DataFrame中\n",
    "df_origin['pred'] = preds  # 将最终的预测类别添加到DataFrame中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c0f577d-6722-47c7-80d1-603e9dc19c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userid</th>\n",
       "      <th>message</th>\n",
       "      <th>ts_created</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ad_prob</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13042</th>\n",
       "      <td>4822375830913754</td>\n",
       "      <td>2162769183</td>\n",
       "      <td>🍽☕️🍰</td>\n",
       "      <td>2022-10-08 19:10:55</td>\n",
       "      <td>0</td>\n",
       "      <td>🍽☕️🍰</td>\n",
       "      <td>0.378869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21280</th>\n",
       "      <td>4820922705642071</td>\n",
       "      <td>7119677364</td>\n",
       "      <td>冬季开业 现在不是冬季是什么[疑问]</td>\n",
       "      <td>2022-10-04 18:56:44</td>\n",
       "      <td>0</td>\n",
       "      <td>冬季开业 现在不是冬季是什么[疑问]</td>\n",
       "      <td>0.710206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8411</th>\n",
       "      <td>4821971952737979</td>\n",
       "      <td>6176975248</td>\n",
       "      <td>#国庆假期最后1天#如果今天你觉得七天很短，那么明天开始，你就会觉得七天很长了[裂开]</td>\n",
       "      <td>2022-10-07 16:26:04</td>\n",
       "      <td>0</td>\n",
       "      <td>#国庆假期最后1天#如果今天你觉得七天很短，那么明天开始，你就会觉得七天很长了[裂开]</td>\n",
       "      <td>0.671589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11910</th>\n",
       "      <td>4818458758614365</td>\n",
       "      <td>5605622990</td>\n",
       "      <td>分享图片</td>\n",
       "      <td>2022-09-27 23:45:53</td>\n",
       "      <td>0</td>\n",
       "      <td>分享图片</td>\n",
       "      <td>0.144969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>4819522551546846</td>\n",
       "      <td>6410240102</td>\n",
       "      <td>分享图片</td>\n",
       "      <td>2022-09-30 22:13:00</td>\n",
       "      <td>0</td>\n",
       "      <td>分享图片</td>\n",
       "      <td>0.144969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>4819645582803688</td>\n",
       "      <td>5367195554</td>\n",
       "      <td>刚刚知道主人将玩具扔柜顶上，猫咪首次捡回失败后，第二次2秒制定路线潇洒完成。 #刚刚知道#</td>\n",
       "      <td>2022-10-01 06:21:54</td>\n",
       "      <td>0</td>\n",
       "      <td>刚刚知道主人将玩具扔柜顶上，猫咪首次捡回失败后，第二次2秒制定路线潇洒完成。 #刚刚知道#</td>\n",
       "      <td>0.649496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18033</th>\n",
       "      <td>4821591760307368</td>\n",
       "      <td>3936801473</td>\n",
       "      <td>[doge]</td>\n",
       "      <td>2022-10-06 15:15:19</td>\n",
       "      <td>0</td>\n",
       "      <td>[doge]</td>\n",
       "      <td>0.708079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18908</th>\n",
       "      <td>4821670345048669</td>\n",
       "      <td>1282849795</td>\n",
       "      <td>#非摄不可##索尼大法好##索尼a7m4#  国庆假期肥东撮街遇到了舞龙表演，看个新鲜！ @...</td>\n",
       "      <td>2022-10-06 20:27:34</td>\n",
       "      <td>0</td>\n",
       "      <td>#非摄不可##索尼大法好##索尼a7m4#  国庆假期肥东撮街遇到了舞龙表演，看个新鲜！ @...</td>\n",
       "      <td>0.686128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14406</th>\n",
       "      <td>4820637301080697</td>\n",
       "      <td>5247208178</td>\n",
       "      <td>[月亮]  [收到] 打工人！好快乐！！！</td>\n",
       "      <td>2022-10-04 00:02:37</td>\n",
       "      <td>0</td>\n",
       "      <td>[月亮]  [收到] 打工人！好快乐！！！</td>\n",
       "      <td>0.726042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10655</th>\n",
       "      <td>4821544843346970</td>\n",
       "      <td>1740304344</td>\n",
       "      <td>兰花村</td>\n",
       "      <td>2022-10-06 12:08:53</td>\n",
       "      <td>0</td>\n",
       "      <td>兰花村</td>\n",
       "      <td>0.457931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id      userid  \\\n",
       "13042  4822375830913754  2162769183   \n",
       "21280  4820922705642071  7119677364   \n",
       "8411   4821971952737979  6176975248   \n",
       "11910  4818458758614365  5605622990   \n",
       "4001   4819522551546846  6410240102   \n",
       "16594  4819645582803688  5367195554   \n",
       "18033  4821591760307368  3936801473   \n",
       "18908  4821670345048669  1282849795   \n",
       "14406  4820637301080697  5247208178   \n",
       "10655  4821544843346970  1740304344   \n",
       "\n",
       "                                                 message           ts_created  \\\n",
       "13042                                               🍽☕️🍰  2022-10-08 19:10:55   \n",
       "21280                                 冬季开业 现在不是冬季是什么[疑问]  2022-10-04 18:56:44   \n",
       "8411         #国庆假期最后1天#如果今天你觉得七天很短，那么明天开始，你就会觉得七天很长了[裂开]  2022-10-07 16:26:04   \n",
       "11910                                               分享图片  2022-09-27 23:45:53   \n",
       "4001                                                分享图片  2022-09-30 22:13:00   \n",
       "16594      刚刚知道主人将玩具扔柜顶上，猫咪首次捡回失败后，第二次2秒制定路线潇洒完成。 #刚刚知道#  2022-10-01 06:21:54   \n",
       "18033                                             [doge]  2022-10-06 15:15:19   \n",
       "18908  #非摄不可##索尼大法好##索尼a7m4#  国庆假期肥东撮街遇到了舞龙表演，看个新鲜！ @...  2022-10-06 20:27:34   \n",
       "14406                              [月亮]  [收到] 打工人！好快乐！！！  2022-10-04 00:02:37   \n",
       "10655                                                兰花村  2022-10-06 12:08:53   \n",
       "\n",
       "       label                                               text   ad_prob  \\\n",
       "13042      0                                               🍽☕️🍰  0.378869   \n",
       "21280      0                                 冬季开业 现在不是冬季是什么[疑问]  0.710206   \n",
       "8411       0        #国庆假期最后1天#如果今天你觉得七天很短，那么明天开始，你就会觉得七天很长了[裂开]  0.671589   \n",
       "11910      0                                               分享图片  0.144969   \n",
       "4001       0                                               分享图片  0.144969   \n",
       "16594      0      刚刚知道主人将玩具扔柜顶上，猫咪首次捡回失败后，第二次2秒制定路线潇洒完成。 #刚刚知道#  0.649496   \n",
       "18033      0                                             [doge]  0.708079   \n",
       "18908      0  #非摄不可##索尼大法好##索尼a7m4#  国庆假期肥东撮街遇到了舞龙表演，看个新鲜！ @...  0.686128   \n",
       "14406      0                              [月亮]  [收到] 打工人！好快乐！！！  0.726042   \n",
       "10655      0                                                兰花村  0.457931   \n",
       "\n",
       "       pred  \n",
       "13042     0  \n",
       "21280     1  \n",
       "8411      1  \n",
       "11910     0  \n",
       "4001      0  \n",
       "16594     1  \n",
       "18033     1  \n",
       "18908     1  \n",
       "14406     1  \n",
       "10655     0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a38d3-274f-4423-8e39-60639b234c3a",
   "metadata": {},
   "source": [
    "## 多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017e8de-e89c-48df-b874-c4644d18b87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39(hsly)",
   "language": "python",
   "name": "hsly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
